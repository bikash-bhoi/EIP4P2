{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initial_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a0e61668995493b93c5d79c112f92c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0f0a47d074641dfa6ae300bfccfec38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3eac328b8ab74a9dbb8f73d5a6d4fa35",
              "IPY_MODEL_bc01fc58c8d74c5d9281743669ca041e"
            ]
          }
        },
        "c0f0a47d074641dfa6ae300bfccfec38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eac328b8ab74a9dbb8f73d5a6d4fa35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efece5f50257403aa499324a6056acf5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14212972,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14212972,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc67123483f242af90420f2eb995def9"
          }
        },
        "bc01fc58c8d74c5d9281743669ca041e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79c58ac7c03b4e9899b5dbff0dcce661",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13.6M/13.6M [00:09&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4121668e9d6c4673a64f432f51000a64"
          }
        },
        "efece5f50257403aa499324a6056acf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc67123483f242af90420f2eb995def9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79c58ac7c03b4e9899b5dbff0dcce661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4121668e9d6c4673a64f432f51000a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eip4-mars/EIP4P2/blob/master/Session2/Initial_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ge6wxTWU7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7a0e61668995493b93c5d79c112f92c4",
            "c0f0a47d074641dfa6ae300bfccfec38",
            "3eac328b8ab74a9dbb8f73d5a6d4fa35",
            "bc01fc58c8d74c5d9281743669ca041e",
            "efece5f50257403aa499324a6056acf5",
            "cc67123483f242af90420f2eb995def9",
            "79c58ac7c03b4e9899b5dbff0dcce661",
            "4121668e9d6c4673a64f432f51000a64"
          ]
        },
        "outputId": "4706d278-2113-4391-f050-5f2739cfff37"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from IPython.display import clear_output\n",
        "\n",
        "use_cuda= torch.cuda.is_available()\n",
        "device=torch.device('cuda' if use_cuda else 'cpu')\n",
        "\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.last_channel, 4)\n",
        "model = nn.Sequential(model, nn.LogSoftmax())\n",
        "model = model.to(device)\n",
        "summary(model, input_size=(3,224,224))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a0e61668995493b93c5d79c112f92c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "         Dropout-157                 [-1, 1280]               0\n",
            "          Linear-158                    [-1, 4]           5,124\n",
            "     MobileNetV2-159                    [-1, 4]               0\n",
            "      LogSoftmax-160                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 2,228,996\n",
            "Trainable params: 2,228,996\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.86\n",
            "Params size (MB): 8.50\n",
            "Estimated Total Size (MB): 161.94\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZVwAltgG9mN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e0328d12-572a-4aec-923f-e3413bae788c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount =True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuDKiGTEqE9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Session\\ 2\\ Dataset.zip\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47UhV4Dg3-lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##rm -rf Session2_Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrgqoh8wi3_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c096fd1-609e-40d7-e72d-5e6c975ca55d"
      },
      "source": [
        "!du -sh Session\\ 2\\ Dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6G\tSession 2 Dataset/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPp74thUETI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"error\")\n",
        "\n",
        "path = \"/content/Session 2 Dataset/\"\n",
        "test_ratio = 0.2\n",
        "\n",
        "\n",
        "def create_dataset_csv_split(path, test_ratio = 0.2):\n",
        "    classes = os.listdir(path)\n",
        "    train = []\n",
        "    test = []\n",
        "    labels = pd.DataFrame(classes,index=range(len(classes)), columns=['Label'])\n",
        "    labels.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "    #print(labels)\n",
        "    for i in range(len(classes)):\n",
        "        child_path = path+classes[i]+'/'\n",
        "        imgs = os.listdir(child_path)\n",
        "        #print(len(tr),classes[i])\n",
        "        trn,tst = train_test_split(imgs, test_size=test_ratio, random_state=42)\n",
        "        \n",
        "        train += [[child_path+x, i] for x in trn]\n",
        "        test += [[child_path+x, i] for x in tst]\n",
        "\n",
        "    # train1 = train.copy()\n",
        "    # test1 = test.copy()\n",
        "\n",
        "    for impath in tqdm(train):\n",
        "        try:\n",
        "            im = Image.open(impath[0])\n",
        "            im.close()\n",
        "        except:\n",
        "            train.remove(impath)\n",
        "            pass\n",
        "\n",
        "    for impath in tqdm(test):\n",
        "        try:\n",
        "            im = Image.open(impath[0])\n",
        "            im.close()\n",
        "        except:\n",
        "            test.remove(impath)\n",
        "            pass\n",
        "\n",
        "    train_df = pd.DataFrame(train,columns=['File_name', 'label_index'])\n",
        "    test_df = pd.DataFrame(test,columns=['File_name', 'label_index'])\n",
        "\n",
        "    print(train_df.shape, test_df.shape, labels.shape)\n",
        "    #train_df_1 = pd.concat([train_df[[\"File_name\"]], pd.get_dummies(train_df.label_index, prefix=\"label\")], axis = 1)\n",
        "    #test_df_1 = pd.concat([test_df[[\"File_name\"]], pd.get_dummies(test_df.label_index, prefix=\"label\")], axis = 1)\n",
        "\n",
        "    train_df.to_csv('train.csv',index=False)\n",
        "    test_df.to_csv('test.csv',index=False)\n",
        "    labels.to_csv('labels.csv',index=False)\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJbrJPsOy4ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "31df50e3-006b-4cc2-a872-4d3b501554e3"
      },
      "source": [
        "create_dataset_csv_split(path,test_ratio)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 16582/16584 [00:02<00:00, 6882.34it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4148/4148 [00:00<00:00, 6798.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(16582, 2) (4148, 2) (4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V0UbdDHYnKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "class custDataset(Dataset):\n",
        "\t\"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "\tdef __init__(self, csv_file, transform=None):\n",
        "\t\tself.frame = pd.read_csv(csv_file, header=0)\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timage_name = self.frame.iloc[idx, 0]\n",
        "\t\tlabel = self.frame.iloc[idx, 1]\n",
        "\t\t\n",
        "\t\timage = Image.open(image_name).convert('RGB')\n",
        "\t\tif self.transform:\n",
        "\t\t\timage = self.transform(image)\n",
        "\t\t#sample = {'image': image, 'label': label}\n",
        "\t\treturn image, label\n",
        "\t\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.frame)\n",
        "\n",
        "def getTrainData(batch_size=64):\n",
        "\t\n",
        "\tstats = {'mean': [0.3931, 0.3785, 0.3606],\n",
        "\t\t\t 'std': [0.1965, 0.1813, 0.1779]}\n",
        "\n",
        "\ttransformed_training = custDataset(csv_file='/content/train.csv',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransform=transforms.Compose([\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.Resize(224),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.RandomHorizontalFlip(),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.RandomRotation(10),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\t\t\ttransforms.Normalize(stats['mean'],stats['std'])\n",
        "\t\t\t\t\t\t\t\t\t\t]))\n",
        "\n",
        "\tdataloader_training = DataLoader(transformed_training, batch_size,\n",
        "\t\t\t\t\t\t\t\t\t shuffle=True, num_workers=4, pin_memory=False)\n",
        "\n",
        "\treturn dataloader_training\n",
        "\n",
        "\n",
        "\n",
        "def getTestData(batch_size=64):\n",
        "\n",
        "\tstats = {'mean': [0.3931, 0.3785, 0.3606],\n",
        "\t\t\t 'std': [0.1965, 0.1813, 0.1779]}\n",
        "\t\n",
        "\ttransformed_testing = custDataset(csv_file='/content/test.csv',\n",
        "\t\t\t\t\t\t\t\t\t\ttransform=transforms.Compose([\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.Resize(224),\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.Normalize(stats['mean'],stats['std'])\n",
        "\t\t\t\t\t\t\t\t\t]))\n",
        "\n",
        "\tdataloader_testing = DataLoader(transformed_testing, batch_size,\n",
        "\t\t\t\t\t\t\t\t\tshuffle=True, num_workers=4, pin_memory=False)\n",
        "\n",
        "\treturn dataloader_testing\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIy4Ucj2ZIwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = getTrainData(64)\n",
        "test_loader = getTestData(64)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LyUEI2Un0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "13d98552-8cf5-41f4-d357-15da3e133422"
      },
      "source": [
        "!git clone https://github.com/eip4-mars/eva4_lib.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'eva4_lib'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYttT072eDsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "df01f0ed-01ad-410b-835c-290e5e6b1a3e"
      },
      "source": [
        "from eva4_lib.utils.train_test import train , test, predict\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,  momentum=0.9)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-06, eps=1e-06)\n",
        "\n",
        "for epoch in range(1, 3):\n",
        "    curr_lr=optimizer.param_groups[0]['lr']\n",
        "    print(f'Epoch: {epoch} Learning_Rate {curr_lr}')\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test_acc1 = test(model, device, test_loader)\n",
        "    print('Test acc:', test_acc1)\n",
        "    scheduler.step(test_acc1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Learning_Rate 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.2260768860578537 Batch_id=259 Accuracy=87.63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [04:21<00:00,  1.00s/it]\n",
            "  0%|          | 0/260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.2981, Accuracy: 3680/4148 (88.72%)\n",
            "\n",
            "Test acc: 88.71745419479267\n",
            "Epoch: 2 Learning_Rate 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.31160905957221985 Batch_id=259 Accuracy=88.80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [04:11<00:00,  1.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3013, Accuracy: 3697/4148 (89.13%)\n",
            "\n",
            "Test acc: 89.12729026036644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQuRolHr5gKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "210b9cad-812a-415e-d572-0606c7441664"
      },
      "source": [
        "fail=[]\n",
        "for eval_data, eval_target in test_loader:\n",
        "  eval_data, eval_target = eval_data.to(device), eval_target.to(device)\n",
        "  eval_out = model(eval_data)\n",
        "  target_lbl=eval_target.cpu().numpy()\n",
        "  pred_lbl=eval_out.argmax(1).cpu().numpy()\n",
        "  #print(pred_lbl)\n",
        "  #print(eval_target)\n",
        "  for i in range(64):\n",
        "    if target_lbl[i] != pred_lbl[i]:fail.append([eval_data[i].cpu(),target_lbl[i],pred_lbl[i],eval_out[i,target_lbl[i]].cpu(),eval_out()[i,pred_lbl[i]].cpu()])\n",
        "  \n",
        "  print('fail_count : '+str(len(fail)))\n",
        "  if len(fail)>100: break\n",
        "\n",
        "print('Returned Miscalssified images # : {}'.format(len(fail)))\n",
        "print('** Note : If count of returned image is less than {}, then there arent enough misclassified images in the loader passed'.format(100))\n",
        "\n",
        "\n",
        "  # fig = plt.figure(figsize=(16,16))\n",
        "  # cnt=0\n",
        "  # for i in fail[:25]:\n",
        "  #   ax=fig.add_subplot(5, 5, cnt+1)\n",
        "  #   img=np.squeeze(eval_data[i].cpu().numpy()[0])\n",
        "  #   ax.imshow(img)\n",
        "  #   cnt+=1\n",
        "  #   ax.set_title(\"Actual : \"+str(target_lbl[i])+\"  Predicted : \"+str(pred_lbl[i]))\n",
        "  # plt.savefig('L1_Misclassified.png')\n",
        "  # plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fail_count : 6\n",
            "fail_count : 10\n",
            "fail_count : 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-adf993ae2360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0meval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtarget_lbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpred_lbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 350\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 11.17 GiB total capacity; 10.29 GiB already allocated; 31.81 MiB free; 10.83 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzhWb7G5PXU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ac65a8e-30c9-4c78-ff8f-8c9881fc7f42"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z1itHmQL25u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66f9071a-b424-49c9-d15a-2275f5bbc77c"
      },
      "source": [
        "fail"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor([[[2.1107, 2.0907, 2.0907,  ..., 2.1506, 2.1705, 2.1705],\n",
              "           [2.1107, 2.0907, 2.0907,  ..., 2.1506, 2.1705, 2.1705],\n",
              "           [2.1107, 2.0907, 2.0907,  ..., 2.1506, 2.1705, 2.1705],\n",
              "           ...,\n",
              "           [1.7913, 1.7913, 1.7913,  ..., 1.8313, 1.8512, 1.8512],\n",
              "           [1.7913, 1.7913, 1.7913,  ..., 1.8313, 1.8512, 1.8512],\n",
              "           [1.7913, 1.7913, 1.7913,  ..., 1.8313, 1.8512, 1.8512]],\n",
              "  \n",
              "          [[2.3681, 2.3465, 2.3465,  ..., 2.4547, 2.4763, 2.4763],\n",
              "           [2.3681, 2.3465, 2.3465,  ..., 2.4547, 2.4763, 2.4763],\n",
              "           [2.3681, 2.3465, 2.3465,  ..., 2.4547, 2.4763, 2.4763],\n",
              "           ...,\n",
              "           [2.0004, 2.0004, 2.0004,  ..., 2.0653, 2.0869, 2.0869],\n",
              "           [2.0004, 2.0004, 2.0004,  ..., 2.0653, 2.0869, 2.0869],\n",
              "           [2.0004, 2.0004, 2.0004,  ..., 2.0653, 2.0869, 2.0869]],\n",
              "  \n",
              "          [[3.2635, 3.2415, 3.2415,  ..., 3.4398, 3.4619, 3.4619],\n",
              "           [3.2635, 3.2415, 3.2415,  ..., 3.4398, 3.4619, 3.4619],\n",
              "           [3.2635, 3.2415, 3.2415,  ..., 3.4398, 3.4619, 3.4619],\n",
              "           ...,\n",
              "           [2.8447, 2.8447, 2.8447,  ..., 2.9769, 2.9990, 2.9990],\n",
              "           [2.8447, 2.8447, 2.8447,  ..., 2.9549, 2.9769, 2.9769],\n",
              "           [2.8447, 2.8447, 2.8447,  ..., 2.9549, 2.9769, 2.9769]]]),\n",
              "  3,\n",
              "  1,\n",
              "  tensor(-1.9443, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.2991, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-1.2022, -1.2022, -1.2222,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           [-1.2022, -1.2022, -1.2022,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           [-1.2022, -1.2022, -1.2022,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           ...,\n",
              "           [ 0.9731,  0.9731,  0.9731,  ...,  0.8334,  0.8334,  0.8334],\n",
              "           [ 0.9731,  0.9731,  0.9731,  ...,  0.8334,  0.8334,  0.8334],\n",
              "           [ 0.9731,  0.9731,  0.9731,  ...,  0.8334,  0.8334,  0.8334]],\n",
              "  \n",
              "          [[ 0.8540,  0.8540,  0.8324,  ...,  0.6377,  0.6377,  0.6377],\n",
              "           [ 0.8540,  0.8540,  0.8540,  ...,  0.6377,  0.6377,  0.6377],\n",
              "           [ 0.8540,  0.8540,  0.8540,  ...,  0.6377,  0.6377,  0.6377],\n",
              "           ...,\n",
              "           [ 1.9572,  1.9572,  1.9572,  ...,  1.9355,  1.9355,  1.9355],\n",
              "           [ 1.9572,  1.9572,  1.9572,  ...,  1.9355,  1.9355,  1.9355],\n",
              "           [ 1.9572,  1.9572,  1.9572,  ...,  1.9355,  1.9355,  1.9355]],\n",
              "  \n",
              "          [[ 2.6022,  2.6022,  2.5801,  ...,  2.4258,  2.4258,  2.4258],\n",
              "           [ 2.6022,  2.6022,  2.6022,  ...,  2.4258,  2.4258,  2.4258],\n",
              "           [ 2.6022,  2.6022,  2.6022,  ...,  2.4258,  2.4258,  2.4258],\n",
              "           ...,\n",
              "           [ 2.9108,  2.9108,  2.9108,  ...,  2.8888,  2.8888,  2.8888],\n",
              "           [ 2.9108,  2.9108,  2.9108,  ...,  2.8888,  2.8888,  2.8888],\n",
              "           [ 2.9108,  2.9108,  2.9108,  ...,  2.8888,  2.8888,  2.8888]]]),\n",
              "  3,\n",
              "  0,\n",
              "  tensor(-1.2176, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.3516, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 0.7137,  0.7336,  0.7336,  ...,  0.7137,  0.7137,  0.7137],\n",
              "           [ 0.7137,  0.7336,  0.7336,  ...,  0.7137,  0.7137,  0.7137],\n",
              "           [ 0.7137,  0.7336,  0.7336,  ...,  0.7137,  0.7137,  0.7137],\n",
              "           ...,\n",
              "           [-0.0048, -0.0248, -0.0048,  ...,  0.9332,  0.9531,  0.8733],\n",
              "           [-0.0846, -0.0647, -0.0447,  ...,  0.6737,  0.6737,  0.6538],\n",
              "           [-0.0846, -0.0846, -0.0447,  ...,  0.5141,  0.4941,  0.4941]],\n",
              "  \n",
              "          [[ 1.4813,  1.5029,  1.5029,  ...,  1.4813,  1.4813,  1.4813],\n",
              "           [ 1.4813,  1.5029,  1.5029,  ...,  1.4813,  1.4813,  1.4813],\n",
              "           [ 1.4813,  1.5029,  1.5029,  ...,  1.4813,  1.4813,  1.4813],\n",
              "           ...,\n",
              "           [ 0.4214,  0.3998,  0.4214,  ...,  0.9838,  0.9622,  0.8973],\n",
              "           [ 0.3349,  0.3565,  0.3782,  ...,  0.8108,  0.7891,  0.7459],\n",
              "           [ 0.3349,  0.3349,  0.3782,  ...,  0.7026,  0.6810,  0.6377]],\n",
              "  \n",
              "          [[ 2.5801,  2.6022,  2.6022,  ...,  2.5801,  2.5801,  2.5801],\n",
              "           [ 2.5801,  2.6022,  2.6022,  ...,  2.5801,  2.5801,  2.5801],\n",
              "           [ 2.5801,  2.6022,  2.6022,  ...,  2.5801,  2.5801,  2.5801],\n",
              "           ...,\n",
              "           [-0.8366, -0.8587, -0.8366,  ..., -0.5501, -0.5941, -0.6823],\n",
              "           [-0.9248, -0.9028, -0.8807,  ..., -0.7264, -0.7484, -0.8587],\n",
              "           [-0.9248, -0.9248, -0.8807,  ..., -0.8587, -0.8807, -0.9248]]]),\n",
              "  3,\n",
              "  0,\n",
              "  tensor(-1.7229, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.2140, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-0.2243, -0.1445, -0.0447,  ..., -0.9428, -0.7831, -0.5836],\n",
              "           [-0.2243, -0.1844, -0.1245,  ..., -0.7831, -0.6434, -0.5037],\n",
              "           [-0.2243, -0.1844, -0.1046,  ..., -0.6235, -0.5636, -0.4638],\n",
              "           ...,\n",
              "           [-1.1224, -1.1224, -1.1024,  ..., -0.9228, -0.9228, -0.9228],\n",
              "           [-1.1424, -1.1424, -1.1424,  ..., -0.9228, -0.9228, -0.9228],\n",
              "           [-1.1623, -1.1623, -1.1623,  ..., -0.9428, -0.9428, -0.9428]],\n",
              "  \n",
              "          [[ 0.2700,  0.3565,  0.4430,  ..., -0.5087, -0.3573, -0.1410],\n",
              "           [ 0.2700,  0.3133,  0.3565,  ..., -0.3573, -0.2059, -0.0545],\n",
              "           [ 0.2700,  0.3133,  0.3782,  ..., -0.1626, -0.1193, -0.0112],\n",
              "           ...,\n",
              "           [-0.7683, -0.7683, -0.7466,  ..., -0.4005, -0.3789, -0.3789],\n",
              "           [-0.7899, -0.7899, -0.7899,  ..., -0.4438, -0.4438, -0.4438],\n",
              "           [-0.8115, -0.8115, -0.8115,  ..., -0.4654, -0.4654, -0.4654]],\n",
              "  \n",
              "          [[ 0.3317,  0.3978,  0.4640,  ..., -0.0651,  0.0672,  0.2876],\n",
              "           [ 0.3317,  0.3537,  0.3758,  ...,  0.0892,  0.2215,  0.3758],\n",
              "           [ 0.3317,  0.3537,  0.3978,  ...,  0.2656,  0.3096,  0.4199],\n",
              "           ...,\n",
              "           [-0.3296, -0.3296, -0.3076,  ...,  0.1994,  0.1994,  0.1994],\n",
              "           [-0.3517, -0.3517, -0.3517,  ...,  0.1553,  0.1553,  0.1553],\n",
              "           [-0.3737, -0.3737, -0.3737,  ...,  0.1333,  0.1333,  0.1333]]]),\n",
              "  3,\n",
              "  0,\n",
              "  tensor(-0.8707, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.5549, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           ...,\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885]],\n",
              "  \n",
              "          [[3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           ...,\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280]],\n",
              "  \n",
              "          [[3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           ...,\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942]]]),\n",
              "  3,\n",
              "  0,\n",
              "  tensor(-2.2210, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.2827, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           ...,\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885],\n",
              "           [3.0885, 3.0885, 3.0885,  ..., 3.0885, 3.0885, 3.0885]],\n",
              "  \n",
              "          [[3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           ...,\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280],\n",
              "           [3.4280, 3.4280, 3.4280,  ..., 3.4280, 3.4280, 3.4280]],\n",
              "  \n",
              "          [[3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           ...,\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942],\n",
              "           [3.5942, 3.5942, 3.5942,  ..., 3.5942, 3.5942, 3.5942]]]),\n",
              "  0,\n",
              "  2,\n",
              "  tensor(-0.8514, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.5760, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 0.3744,  0.3744,  0.3943,  ..., -0.0447, -0.1445, -0.1844],\n",
              "           [ 0.4143,  0.4143,  0.4143,  ..., -0.1245, -0.1645, -0.1844],\n",
              "           [ 0.4343,  0.4343,  0.4343,  ..., -0.1445, -0.2243, -0.2243],\n",
              "           ...,\n",
              "           [ 0.5740,  0.6139,  0.6538,  ...,  0.6937,  0.6937,  0.6538],\n",
              "           [ 0.6139,  0.6538,  0.6737,  ...,  0.6737,  0.6338,  0.6139],\n",
              "           [ 0.6338,  0.6937,  0.7137,  ...,  0.6538,  0.6139,  0.5939]],\n",
              "  \n",
              "          [[ 0.1402,  0.1402,  0.1618,  ...,  0.4647,  0.3998,  0.3565],\n",
              "           [ 0.1835,  0.1835,  0.1835,  ...,  0.3782,  0.3782,  0.3565],\n",
              "           [ 0.2051,  0.2051,  0.2051,  ...,  0.3565,  0.3133,  0.3133],\n",
              "           ...,\n",
              "           [ 0.8324,  0.8540,  0.8973,  ...,  1.0271,  1.0271,  0.9838],\n",
              "           [ 0.8108,  0.7891,  0.8324,  ...,  1.0271,  1.0271,  1.0054],\n",
              "           [ 0.8108,  0.7675,  0.7891,  ...,  1.0271,  1.0487,  1.0271]],\n",
              "  \n",
              "          [[-1.0571, -1.0571, -1.0350,  ..., -0.8146, -0.9028, -0.9468],\n",
              "           [-1.0130, -1.0130, -1.0130,  ..., -0.9028, -0.9248, -0.9468],\n",
              "           [-0.9909, -0.9909, -0.9909,  ..., -0.9028, -0.9689, -0.9909],\n",
              "           ...,\n",
              "           [-0.8587, -0.8366, -0.7925,  ..., -0.6823, -0.6823, -0.7264],\n",
              "           [-0.8587, -0.8366, -0.7925,  ..., -0.7044, -0.7044, -0.7264],\n",
              "           [-0.8587, -0.8587, -0.7925,  ..., -0.7044, -0.7044, -0.7264]]]),\n",
              "  2,\n",
              "  3,\n",
              "  tensor(-1.8670, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.7141, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-0.0248, -0.0248, -0.0248,  ..., -0.2842, -0.2842, -0.3042],\n",
              "           [-0.0048, -0.0048, -0.0048,  ..., -0.2842, -0.2842, -0.2842],\n",
              "           [-0.0048, -0.0048, -0.0048,  ..., -0.2642, -0.2842, -0.2842],\n",
              "           ...,\n",
              "           [-0.6434, -0.6434, -0.6434,  ..., -0.8630, -0.9228, -0.9428],\n",
              "           [-0.6235, -0.5836, -0.6235,  ..., -0.8430, -0.8829, -0.9228],\n",
              "           [-0.4638, -0.4239, -0.4638,  ..., -0.8031, -0.8829, -0.9428]],\n",
              "  \n",
              "          [[ 1.5462,  1.5462,  1.5462,  ...,  1.3948,  1.3948,  1.3731],\n",
              "           [ 1.5678,  1.5678,  1.5678,  ...,  1.3948,  1.3948,  1.3948],\n",
              "           [ 1.5678,  1.5678,  1.5678,  ...,  1.4164,  1.3948,  1.3948],\n",
              "           ...,\n",
              "           [-0.7250, -0.7250, -0.7250,  ..., -1.3306, -1.3523, -1.3523],\n",
              "           [-0.7034, -0.6601, -0.7034,  ..., -1.2874, -1.3090, -1.3306],\n",
              "           [-0.5303, -0.4871, -0.5303,  ..., -1.2657, -1.3090, -1.3306]],\n",
              "  \n",
              "          [[ 3.1974,  3.1974,  3.1974,  ...,  3.0210,  3.0210,  2.9990],\n",
              "           [ 3.2194,  3.2194,  3.2194,  ...,  3.0210,  3.0210,  3.0210],\n",
              "           [ 3.2194,  3.2194,  3.2194,  ...,  3.0431,  3.0210,  3.0210],\n",
              "           ...,\n",
              "           [-0.7044, -0.7044, -0.7044,  ..., -1.4318, -1.4538, -1.4318],\n",
              "           [-0.6823, -0.6382, -0.6823,  ..., -1.4538, -1.4318, -1.4098],\n",
              "           [-0.5060, -0.4619, -0.5060,  ..., -1.4538, -1.4759, -1.4759]]]),\n",
              "  0,\n",
              "  2,\n",
              "  tensor(-2.1153, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.2740, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-0.6634, -0.6634, -0.6434,  ..., -0.6833, -0.6634, -0.6833],\n",
              "           [-0.6634, -0.6634, -0.6434,  ..., -0.6833, -0.6634, -0.6833],\n",
              "           [-0.6634, -0.6634, -0.6434,  ..., -0.6833, -0.6634, -0.6833],\n",
              "           ...,\n",
              "           [-0.4439, -0.4439, -0.4439,  ..., -0.5037, -0.5037, -0.5037],\n",
              "           [-0.4439, -0.4439, -0.4439,  ..., -0.5037, -0.5037, -0.5037],\n",
              "           [-0.4439, -0.4439, -0.4439,  ..., -0.5037, -0.5037, -0.5037]],\n",
              "  \n",
              "          [[ 0.3565,  0.3565,  0.3349,  ...,  0.3133,  0.3349,  0.3133],\n",
              "           [ 0.3565,  0.3565,  0.3349,  ...,  0.3133,  0.3349,  0.3133],\n",
              "           [ 0.3565,  0.3565,  0.3349,  ...,  0.3133,  0.3349,  0.3133],\n",
              "           ...,\n",
              "           [ 0.6593,  0.6593,  0.6593,  ...,  0.5945,  0.5945,  0.5945],\n",
              "           [ 0.6593,  0.6593,  0.6593,  ...,  0.5945,  0.5945,  0.5945],\n",
              "           [ 0.6593,  0.6593,  0.6593,  ...,  0.5945,  0.5945,  0.5945]],\n",
              "  \n",
              "          [[ 1.7866,  1.7866,  1.7866,  ...,  1.7204,  1.7425,  1.7204],\n",
              "           [ 1.7866,  1.7866,  1.7866,  ...,  1.7204,  1.7425,  1.7204],\n",
              "           [ 1.7866,  1.7866,  1.7866,  ...,  1.7204,  1.7425,  1.7204],\n",
              "           ...,\n",
              "           [ 2.0511,  2.0511,  2.0511,  ...,  1.9850,  1.9850,  1.9850],\n",
              "           [ 2.0511,  2.0511,  2.0511,  ...,  1.9850,  1.9850,  1.9850],\n",
              "           [ 2.0511,  2.0511,  2.0511,  ...,  1.9850,  1.9850,  1.9850]]]),\n",
              "  0,\n",
              "  3,\n",
              "  tensor(-0.9196, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.7588, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-2.0005, -2.0005, -2.0005,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           [-2.0005, -2.0005, -2.0005,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           [-2.0005, -2.0005, -2.0005,  ..., -2.0005, -2.0005, -2.0005],\n",
              "           ...,\n",
              "           [ 3.0686,  3.0686,  3.0686,  ...,  3.0686,  3.0686,  3.0686],\n",
              "           [ 3.0686,  3.0686,  3.0686,  ...,  3.0686,  3.0686,  3.0686],\n",
              "           [ 3.0686,  3.0686,  3.0686,  ...,  3.0686,  3.0686,  3.0686]],\n",
              "  \n",
              "          [[-2.0877, -2.0877, -2.0877,  ..., -2.0877, -2.0877, -2.0877],\n",
              "           [-2.0877, -2.0877, -2.0877,  ..., -2.0877, -2.0877, -2.0877],\n",
              "           [-2.0877, -2.0877, -2.0877,  ..., -2.0877, -2.0877, -2.0877],\n",
              "           ...,\n",
              "           [ 3.4064,  3.4064,  3.4064,  ...,  3.4064,  3.4064,  3.4064],\n",
              "           [ 3.4064,  3.4064,  3.4064,  ...,  3.4064,  3.4064,  3.4064],\n",
              "           [ 3.4064,  3.4064,  3.4064,  ...,  3.4064,  3.4064,  3.4064]],\n",
              "  \n",
              "          [[-2.0270, -2.0270, -2.0270,  ..., -2.0270, -2.0270, -2.0270],\n",
              "           [-2.0270, -2.0270, -2.0270,  ..., -2.0270, -2.0270, -2.0270],\n",
              "           [-2.0270, -2.0270, -2.0270,  ..., -2.0270, -2.0270, -2.0270],\n",
              "           ...,\n",
              "           [ 3.5721,  3.5721,  3.5721,  ...,  3.5721,  3.5721,  3.5721],\n",
              "           [ 3.5721,  3.5721,  3.5721,  ...,  3.5721,  3.5721,  3.5721],\n",
              "           [ 3.5721,  3.5721,  3.5721,  ...,  3.5721,  3.5721,  3.5721]]]),\n",
              "  2,\n",
              "  0,\n",
              "  tensor(-1.4656, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.3456, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 0.3145,  0.3145,  0.3345,  ...,  0.2946,  0.3345,  0.3744],\n",
              "           [ 0.2946,  0.2946,  0.3345,  ...,  0.4143,  0.4742,  0.4941],\n",
              "           [ 0.3544,  0.3943,  0.4343,  ...,  0.5740,  0.5740,  0.5740],\n",
              "           ...,\n",
              "           [-0.6634, -0.5836, -0.6634,  ..., -0.9428, -0.8430, -0.8430],\n",
              "           [-0.5636, -0.4838, -0.5836,  ..., -0.9627, -0.8630, -0.9029],\n",
              "           [-0.5636, -0.4838, -0.5636,  ..., -0.9228, -0.8230, -0.8829]],\n",
              "  \n",
              "          [[ 0.9405,  0.9405,  0.9622,  ...,  0.6810,  0.7242,  0.7675],\n",
              "           [ 0.8973,  0.9189,  0.9405,  ...,  0.8324,  0.8973,  0.9189],\n",
              "           [ 0.9189,  0.9622,  1.0054,  ...,  0.9622,  0.9838,  0.9622],\n",
              "           ...,\n",
              "           [-0.5736, -0.4871, -0.5520,  ..., -0.7034, -0.5952, -0.5952],\n",
              "           [-0.4654, -0.3789, -0.4654,  ..., -0.7250, -0.6168, -0.6601],\n",
              "           [-0.4654, -0.3789, -0.4438,  ..., -0.6817, -0.5736, -0.6385]],\n",
              "  \n",
              "          [[ 2.6463,  2.6463,  2.6463,  ...,  2.2936,  2.3377,  2.3818],\n",
              "           [ 2.5581,  2.5581,  2.5581,  ...,  2.4038,  2.4699,  2.4920],\n",
              "           [ 2.4920,  2.5361,  2.5361,  ...,  2.5140,  2.5140,  2.5140],\n",
              "           ...,\n",
              "           [-1.1673, -1.0791, -1.1452,  ..., -1.3657, -1.2555, -1.2555],\n",
              "           [-1.0571, -0.9689, -1.0571,  ..., -1.3877, -1.2775, -1.3216],\n",
              "           [-1.0571, -0.9689, -1.0350,  ..., -1.3436, -1.2334, -1.2995]]]),\n",
              "  0,\n",
              "  3,\n",
              "  tensor(-1.0430, grad_fn=<SelectBackward>),\n",
              "  tensor(-1.0030, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 1.4521,  1.3722,  1.3124,  ...,  1.7315,  1.7913,  1.8712],\n",
              "           [ 1.1727,  1.0928,  1.0529,  ...,  1.7514,  1.8113,  1.8911],\n",
              "           [ 0.8933,  0.8134,  0.7735,  ...,  1.7913,  1.8313,  1.9111],\n",
              "           ...,\n",
              "           [ 0.2546,  0.2147,  0.1748,  ..., -0.0846, -0.0647, -0.0647],\n",
              "           [ 0.2347,  0.2147,  0.1748,  ..., -0.0846, -0.0647, -0.0647],\n",
              "           [ 0.2546,  0.2147,  0.1748,  ..., -0.0846, -0.0647, -0.0647]],\n",
              "  \n",
              "          [[ 1.5894,  1.5029,  1.4380,  ...,  1.9139,  2.0004,  2.0869],\n",
              "           [ 1.3083,  1.2217,  1.1568,  ...,  1.9355,  2.0221,  2.1086],\n",
              "           [ 1.0054,  0.9189,  0.8756,  ...,  1.9788,  2.0437,  2.1302],\n",
              "           ...,\n",
              "           [ 0.3349,  0.2916,  0.2484,  ..., -0.1193, -0.1193, -0.1193],\n",
              "           [ 0.3349,  0.3133,  0.2700,  ..., -0.1193, -0.1193, -0.1193],\n",
              "           [ 0.3565,  0.3133,  0.2700,  ..., -0.1193, -0.1193, -0.1193]],\n",
              "  \n",
              "          [[ 1.9629,  1.8747,  1.8086,  ...,  2.3818,  2.4699,  2.5581],\n",
              "           [ 1.6764,  1.5882,  1.5220,  ...,  2.4038,  2.4699,  2.5581],\n",
              "           [ 1.3898,  1.3016,  1.2575,  ...,  2.4258,  2.4920,  2.5801],\n",
              "           ...,\n",
              "           [-0.3076, -0.3296, -0.3737,  ..., -0.5941, -0.5721, -0.5721],\n",
              "           [-0.3076, -0.3296, -0.3737,  ..., -0.5721, -0.5501, -0.5501],\n",
              "           [-0.2855, -0.3296, -0.3737,  ..., -0.5721, -0.5501, -0.5501]]]),\n",
              "  2,\n",
              "  3,\n",
              "  tensor(-1.2750, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.8225, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 2.1506,  2.1506,  2.1306,  ...,  2.6695,  2.6695,  2.6495],\n",
              "           [ 2.1905,  2.1905,  2.1705,  ...,  2.6894,  2.6894,  2.6695],\n",
              "           [ 2.2104,  2.2104,  2.1905,  ...,  2.7293,  2.7493,  2.7493],\n",
              "           ...,\n",
              "           [-0.3640, -0.2243, -0.2044,  ...,  0.1149,  0.0750,  0.1549],\n",
              "           [-0.2243, -0.1245, -0.1645,  ...,  0.1349,  0.1948,  0.2746],\n",
              "           [-0.2044, -0.1844, -0.1445,  ...,  0.0351,  0.0351,  0.0750]],\n",
              "  \n",
              "          [[ 2.6493,  2.6493,  2.6277,  ...,  3.1468,  3.1252,  3.1036],\n",
              "           [ 2.6926,  2.6926,  2.6710,  ...,  3.1685,  3.1468,  3.1252],\n",
              "           [ 2.7142,  2.7142,  2.6926,  ...,  3.1901,  3.1901,  3.1901],\n",
              "           ...,\n",
              "           [ 0.1618,  0.2484,  0.2267,  ...,  0.4214,  0.4214,  0.5079],\n",
              "           [ 0.2916,  0.3782,  0.2484,  ...,  0.4863,  0.5945,  0.6377],\n",
              "           [ 0.2700,  0.2916,  0.2700,  ...,  0.3782,  0.4214,  0.4214]],\n",
              "  \n",
              "          [[ 3.4839,  3.4839,  3.5280,  ...,  3.5942,  3.5942,  3.5942],\n",
              "           [ 3.5280,  3.5280,  3.5721,  ...,  3.5942,  3.5942,  3.5942],\n",
              "           [ 3.5501,  3.5501,  3.5942,  ...,  3.5942,  3.5942,  3.5942],\n",
              "           ...,\n",
              "           [-1.2555, -1.1893, -1.1452,  ..., -0.9248, -0.9468, -0.8587],\n",
              "           [-1.1232, -1.0571, -1.1232,  ..., -0.9028, -0.7925, -0.7264],\n",
              "           [-1.1452, -1.1452, -1.1011,  ..., -1.0130, -0.9468, -0.9468]]]),\n",
              "  0,\n",
              "  3,\n",
              "  tensor(-0.8496, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.8120, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-0.2243, -0.2243, -0.2243,  ..., -0.2044, -0.2044, -0.2044],\n",
              "           [-0.2243, -0.2243, -0.2243,  ..., -0.2044, -0.2044, -0.2044],\n",
              "           [-0.2243, -0.2243, -0.2243,  ..., -0.2044, -0.2044, -0.2044],\n",
              "           ...,\n",
              "           [-0.1046, -0.0846, -0.1046,  ..., -0.1046, -0.1046, -0.1046],\n",
              "           [-0.1046, -0.0846, -0.1046,  ..., -0.1046, -0.1046, -0.0846],\n",
              "           [-0.1046, -0.0846, -0.1046,  ..., -0.1046, -0.1046, -0.0846]],\n",
              "  \n",
              "          [[ 1.0054,  1.0054,  1.0054,  ...,  0.9622,  0.9622,  0.9622],\n",
              "           [ 1.0054,  1.0054,  1.0054,  ...,  0.9622,  0.9622,  0.9622],\n",
              "           [ 1.0054,  1.0054,  1.0054,  ...,  0.9622,  0.9622,  0.9622],\n",
              "           ...,\n",
              "           [ 1.1785,  1.2001,  1.1785,  ...,  1.1352,  1.1352,  1.1352],\n",
              "           [ 1.1785,  1.2001,  1.1785,  ...,  1.1352,  1.1352,  1.1568],\n",
              "           [ 1.1785,  1.2001,  1.1785,  ...,  1.1352,  1.1352,  1.1568]],\n",
              "  \n",
              "          [[ 3.1092,  3.1092,  3.1092,  ...,  3.0431,  3.0431,  3.0431],\n",
              "           [ 3.1092,  3.1092,  3.1092,  ...,  3.0431,  3.0431,  3.0431],\n",
              "           [ 3.1092,  3.1092,  3.1092,  ...,  3.0431,  3.0431,  3.0431],\n",
              "           ...,\n",
              "           [ 3.2194,  3.2415,  3.2194,  ...,  3.1974,  3.1974,  3.1974],\n",
              "           [ 3.2194,  3.2415,  3.2194,  ...,  3.1974,  3.1974,  3.2194],\n",
              "           [ 3.2194,  3.2415,  3.2194,  ...,  3.1974,  3.1974,  3.2194]]]),\n",
              "  0,\n",
              "  2,\n",
              "  tensor(-1.1456, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.7199, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[1.4122, 1.4122, 1.4122,  ..., 1.6716, 1.6716, 1.6716],\n",
              "           [1.3922, 1.3922, 1.3922,  ..., 1.6317, 1.6317, 1.6317],\n",
              "           [1.3722, 1.3722, 1.3722,  ..., 1.5918, 1.5918, 1.5918],\n",
              "           ...,\n",
              "           [2.3901, 2.3901, 2.3901,  ..., 1.9111, 1.8911, 1.8712],\n",
              "           [2.4699, 2.4699, 2.4699,  ..., 2.0308, 2.0109, 1.9710],\n",
              "           [2.5098, 2.5098, 2.5098,  ..., 2.0907, 2.0508, 2.0109]],\n",
              "  \n",
              "          [[2.2816, 2.2816, 2.2816,  ..., 2.4114, 2.4114, 2.4114],\n",
              "           [2.2600, 2.2600, 2.2600,  ..., 2.3681, 2.3681, 2.3681],\n",
              "           [2.2384, 2.2384, 2.2384,  ..., 2.3249, 2.3249, 2.3249],\n",
              "           ...,\n",
              "           [2.6926, 2.6926, 2.6926,  ..., 2.4114, 2.4114, 2.3898],\n",
              "           [2.7791, 2.7791, 2.7791,  ..., 2.5412, 2.5195, 2.4979],\n",
              "           [2.8224, 2.8224, 2.8224,  ..., 2.5844, 2.5412, 2.4979]],\n",
              "  \n",
              "          [[3.3958, 3.3958, 3.3958,  ..., 3.3076, 3.3076, 3.3076],\n",
              "           [3.3737, 3.3737, 3.3737,  ..., 3.2635, 3.2635, 3.2635],\n",
              "           [3.3517, 3.3517, 3.3517,  ..., 3.2194, 3.2194, 3.2194],\n",
              "           ...,\n",
              "           [2.9549, 2.9549, 2.9549,  ..., 2.8888, 2.9108, 2.8888],\n",
              "           [3.0431, 3.0431, 3.0431,  ..., 2.9990, 2.9769, 2.9990],\n",
              "           [3.0651, 3.0651, 3.0651,  ..., 3.0651, 3.0431, 3.0431]]]),\n",
              "  2,\n",
              "  1,\n",
              "  tensor(-9.9940, grad_fn=<SelectBackward>),\n",
              "  tensor(-5.1498e-05, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[ 0.4742,  0.3145,  0.1948,  ..., -0.6035, -0.7233, -0.7432],\n",
              "           [ 0.2347,  0.0950, -0.0647,  ..., -0.6634, -0.7632, -0.8430],\n",
              "           [ 0.1948,  0.1349,  0.0950,  ..., -0.7233, -0.7831, -0.8630],\n",
              "           ...,\n",
              "           [ 2.5098,  2.4499,  2.4898,  ...,  2.1905,  2.2703,  2.3102],\n",
              "           [ 2.4699,  2.4300,  2.4499,  ...,  2.2304,  2.2104,  2.2504],\n",
              "           [ 2.4699,  2.4499,  2.4300,  ...,  2.2104,  2.1705,  2.1905]],\n",
              "  \n",
              "          [[ 1.1136,  0.9622,  0.8756,  ...,  0.1186,  0.0970,  0.0537],\n",
              "           [ 0.8540,  0.7459,  0.5945,  ...,  0.0753,  0.0537, -0.0328],\n",
              "           [ 0.8756,  0.8324,  0.8108,  ...,  0.0753,  0.0537, -0.0112],\n",
              "           ...,\n",
              "           [ 2.7575,  2.6926,  2.7575,  ...,  2.5195,  2.6277,  2.6710],\n",
              "           [ 2.7142,  2.6710,  2.7142,  ...,  2.5628,  2.5628,  2.6277],\n",
              "           [ 2.7359,  2.7142,  2.6926,  ...,  2.5412,  2.5412,  2.5628]],\n",
              "  \n",
              "          [[ 1.1694,  1.0812,  1.0591,  ...,  0.4640,  0.4199,  0.3758],\n",
              "           [ 0.8828,  0.7946,  0.7285,  ...,  0.4199,  0.3537,  0.2656],\n",
              "           [ 0.7946,  0.8167,  0.8387,  ...,  0.3758,  0.3317,  0.2876],\n",
              "           ...,\n",
              "           [ 0.9930,  0.9269,  0.9269,  ...,  0.5301,  0.6623,  0.7285],\n",
              "           [ 0.9269,  0.8828,  0.8607,  ...,  0.6183,  0.5962,  0.5962],\n",
              "           [ 0.9048,  0.8828,  0.8387,  ...,  0.5742,  0.4860,  0.4640]]]),\n",
              "  3,\n",
              "  0,\n",
              "  tensor(-3.1649, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.0616, grad_fn=<SelectBackward>)],\n",
              " [tensor([[[-0.3042, -0.3042, -0.3042,  ...,  0.5939,  0.6737,  0.7735],\n",
              "           [-0.3042, -0.3042, -0.3042,  ...,  0.5340,  0.6139,  0.7137],\n",
              "           [-0.3042, -0.3042, -0.2842,  ...,  0.4542,  0.5540,  0.6538],\n",
              "           ...,\n",
              "           [-0.0647, -0.0447, -0.0447,  ...,  0.6139,  0.6139,  0.6139],\n",
              "           [-0.0447, -0.0248, -0.0048,  ...,  0.6139,  0.6139,  0.6139],\n",
              "           [-0.0248, -0.0048, -0.0447,  ...,  0.5939,  0.5939,  0.5939]],\n",
              "  \n",
              "          [[-0.0977, -0.0977, -0.0977,  ...,  0.6377,  0.6810,  0.7459],\n",
              "           [-0.0977, -0.0977, -0.0977,  ...,  0.5728,  0.6161,  0.6593],\n",
              "           [-0.0977, -0.0977, -0.0761,  ...,  0.4863,  0.5512,  0.5945],\n",
              "           ...,\n",
              "           [-0.1626, -0.1410, -0.1193,  ...,  0.3565,  0.3565,  0.3565],\n",
              "           [-0.1410, -0.1193, -0.0761,  ...,  0.3565,  0.3565,  0.3565],\n",
              "           [-0.1193, -0.0977, -0.1193,  ...,  0.3782,  0.3782,  0.3782]],\n",
              "  \n",
              "          [[-0.3517, -0.3517, -0.3517,  ..., -0.0651,  0.0010,  0.0672],\n",
              "           [-0.3517, -0.3517, -0.3517,  ..., -0.1312, -0.0651,  0.0451],\n",
              "           [-0.3517, -0.3517, -0.3296,  ..., -0.2194, -0.1312, -0.0210],\n",
              "           ...,\n",
              "           [-0.8807, -0.8587, -0.8366,  ..., -0.0651, -0.0651, -0.0651],\n",
              "           [-0.8587, -0.8366, -0.8146,  ..., -0.0651, -0.0651, -0.0651],\n",
              "           [-0.8807, -0.8587, -0.8807,  ..., -0.0651, -0.0651, -0.0651]]]),\n",
              "  2,\n",
              "  3,\n",
              "  tensor(-4.5493, grad_fn=<SelectBackward>),\n",
              "  tensor(-0.3767, grad_fn=<SelectBackward>)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn0SYJJe23_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(torch.device('cpu'))\n",
        "model.eval()\n",
        "traced_model = torch.jit.trace(model,torch.randn(1,3,244,244))\n",
        "traced_model.save(\"Sess2_mobilenetv2_4.pt\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7tpvOVYgOjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}