{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4P2_Session2_Mobilenetv2_custom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eip4-mars/EIP4P2/blob/master/Session2/EVA4P2_Session2_Mobilenetv2_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO5xeknM-Hvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9a3364de-c61a-498b-9ee7-5f14cd23b3c0"
      },
      "source": [
        "!rm -rf eva4_lib\n",
        "!git clone https://github.com/eip4-mars/eva4_lib.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'eva4_lib'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/62)\u001b[K\rremote: Counting objects:   3% (2/62)\u001b[K\rremote: Counting objects:   4% (3/62)\u001b[K\rremote: Counting objects:   6% (4/62)\u001b[K\rremote: Counting objects:   8% (5/62)\u001b[K\rremote: Counting objects:   9% (6/62)\u001b[K\rremote: Counting objects:  11% (7/62)\u001b[K\rremote: Counting objects:  12% (8/62)\u001b[K\rremote: Counting objects:  14% (9/62)\u001b[K\rremote: Counting objects:  16% (10/62)\u001b[K\rremote: Counting objects:  17% (11/62)\u001b[K\rremote: Counting objects:  19% (12/62)\u001b[K\rremote: Counting objects:  20% (13/62)\u001b[K\rremote: Counting objects:  22% (14/62)\u001b[K\rremote: Counting objects:  24% (15/62)\u001b[K\rremote: Counting objects:  25% (16/62)\u001b[K\rremote: Counting objects:  27% (17/62)\u001b[K\rremote: Counting objects:  29% (18/62)\u001b[K\rremote: Counting objects:  30% (19/62)\u001b[K\rremote: Counting objects:  32% (20/62)\u001b[K\rremote: Counting objects:  33% (21/62)\u001b[K\rremote: Counting objects:  35% (22/62)\u001b[K\rremote: Counting objects:  37% (23/62)\u001b[K\rremote: Counting objects:  38% (24/62)\u001b[K\rremote: Counting objects:  40% (25/62)\u001b[K\rremote: Counting objects:  41% (26/62)\u001b[K\rremote: Counting objects:  43% (27/62)\u001b[K\rremote: Counting objects:  45% (28/62)\u001b[K\rremote: Counting objects:  46% (29/62)\u001b[K\rremote: Counting objects:  48% (30/62)\u001b[K\rremote: Counting objects:  50% (31/62)\u001b[K\rremote: Counting objects:  51% (32/62)\u001b[K\rremote: Counting objects:  53% (33/62)\u001b[K\rremote: Counting objects:  54% (34/62)\u001b[K\rremote: Counting objects:  56% (35/62)\u001b[K\rremote: Counting objects:  58% (36/62)\u001b[K\rremote: Counting objects:  59% (37/62)\u001b[K\rremote: Counting objects:  61% (38/62)\u001b[K\rremote: Counting objects:  62% (39/62)\u001b[K\rremote: Counting objects:  64% (40/62)\u001b[K\rremote: Counting objects:  66% (41/62)\u001b[K\rremote: Counting objects:  67% (42/62)\u001b[K\rremote: Counting objects:  69% (43/62)\u001b[K\rremote: Counting objects:  70% (44/62)\u001b[K\rremote: Counting objects:  72% (45/62)\u001b[K\rremote: Counting objects:  74% (46/62)\u001b[K\rremote: Counting objects:  75% (47/62)\u001b[K\rremote: Counting objects:  77% (48/62)\u001b[K\rremote: Counting objects:  79% (49/62)\u001b[K\rremote: Counting objects:  80% (50/62)\u001b[K\rremote: Counting objects:  82% (51/62)\u001b[K\rremote: Counting objects:  83% (52/62)\u001b[K\rremote: Counting objects:  85% (53/62)\u001b[K\rremote: Counting objects:  87% (54/62)\u001b[K\rremote: Counting objects:  88% (55/62)\u001b[K\rremote: Counting objects:  90% (56/62)\u001b[K\rremote: Counting objects:  91% (57/62)\u001b[K\rremote: Counting objects:  93% (58/62)\u001b[K\rremote: Counting objects:  95% (59/62)\u001b[K\rremote: Counting objects:  96% (60/62)\u001b[K\rremote: Counting objects:  98% (61/62)\u001b[K\rremote: Counting objects: 100% (62/62)\u001b[K\rremote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/59)\u001b[K\rremote: Compressing objects:   3% (2/59)\u001b[K\rremote: Compressing objects:   5% (3/59)\u001b[K\rremote: Compressing objects:   6% (4/59)\u001b[K\rremote: Compressing objects:   8% (5/59)\u001b[K\rremote: Compressing objects:  10% (6/59)\u001b[K\rremote: Compressing objects:  11% (7/59)\u001b[K\rremote: Compressing objects:  13% (8/59)\u001b[K\rremote: Compressing objects:  15% (9/59)\u001b[K\rremote: Compressing objects:  16% (10/59)\u001b[K\rremote: Compressing objects:  18% (11/59)\u001b[K\rremote: Compressing objects:  20% (12/59)\u001b[K\rremote: Compressing objects:  22% (13/59)\u001b[K\rremote: Compressing objects:  23% (14/59)\u001b[K\rremote: Compressing objects:  25% (15/59)\u001b[K\rremote: Compressing objects:  27% (16/59)\u001b[K\rremote: Compressing objects:  28% (17/59)\u001b[K\rremote: Compressing objects:  30% (18/59)\u001b[K\rremote: Compressing objects:  32% (19/59)\u001b[K\rremote: Compressing objects:  33% (20/59)\u001b[K\rremote: Compressing objects:  35% (21/59)\u001b[K\rremote: Compressing objects:  37% (22/59)\u001b[K\rremote: Compressing objects:  38% (23/59)\u001b[K\rremote: Compressing objects:  40% (24/59)\u001b[K\rremote: Compressing objects:  42% (25/59)\u001b[K\rremote: Compressing objects:  44% (26/59)\u001b[K\rremote: Compressing objects:  45% (27/59)\u001b[K\rremote: Compressing objects:  47% (28/59)\u001b[K\rremote: Compressing objects:  49% (29/59)\u001b[K\rremote: Compressing objects:  50% (30/59)\u001b[K\rremote: Compressing objects:  52% (31/59)\u001b[K\rremote: Compressing objects:  54% (32/59)\u001b[K\rremote: Compressing objects:  55% (33/59)\u001b[K\rremote: Compressing objects:  57% (34/59)\u001b[K\rremote: Compressing objects:  59% (35/59)\u001b[K\rremote: Compressing objects:  61% (36/59)\u001b[K\rremote: Compressing objects:  62% (37/59)\u001b[K\rremote: Compressing objects:  64% (38/59)\u001b[K\rremote: Compressing objects:  66% (39/59)\u001b[K\rremote: Compressing objects:  67% (40/59)\u001b[K\rremote: Compressing objects:  69% (41/59)\u001b[K\rremote: Compressing objects:  71% (42/59)\u001b[K\rremote: Compressing objects:  72% (43/59)\u001b[K\rremote: Compressing objects:  74% (44/59)\u001b[K\rremote: Compressing objects:  76% (45/59)\u001b[K\rremote: Compressing objects:  77% (46/59)\u001b[K\rremote: Compressing objects:  79% (47/59)\u001b[K\rremote: Compressing objects:  81% (48/59)\u001b[K\rremote: Compressing objects:  83% (49/59)\u001b[K\rremote: Compressing objects:  84% (50/59)\u001b[K\rremote: Compressing objects:  86% (51/59)\u001b[K\rremote: Compressing objects:  88% (52/59)\u001b[K\rremote: Compressing objects:  89% (53/59)\u001b[K\rremote: Compressing objects:  91% (54/59)\u001b[K\rremote: Compressing objects:  93% (55/59)\u001b[K\rremote: Compressing objects:  94% (56/59)\u001b[K\rremote: Compressing objects:  96% (57/59)\u001b[K\rremote: Compressing objects:  98% (58/59)\u001b[K\rremote: Compressing objects: 100% (59/59)\u001b[K\rremote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "Unpacking objects:   1% (1/62)   \rUnpacking objects:   3% (2/62)   \rUnpacking objects:   4% (3/62)   \rUnpacking objects:   6% (4/62)   \rUnpacking objects:   8% (5/62)   \rUnpacking objects:   9% (6/62)   \rUnpacking objects:  11% (7/62)   \rUnpacking objects:  12% (8/62)   \rUnpacking objects:  14% (9/62)   \rUnpacking objects:  16% (10/62)   \rUnpacking objects:  17% (11/62)   \rUnpacking objects:  19% (12/62)   \rUnpacking objects:  20% (13/62)   \rUnpacking objects:  22% (14/62)   \rUnpacking objects:  24% (15/62)   \rUnpacking objects:  25% (16/62)   \rUnpacking objects:  27% (17/62)   \rUnpacking objects:  29% (18/62)   \rUnpacking objects:  30% (19/62)   \rUnpacking objects:  32% (20/62)   \rUnpacking objects:  33% (21/62)   \rUnpacking objects:  35% (22/62)   \rUnpacking objects:  37% (23/62)   \rUnpacking objects:  38% (24/62)   \rUnpacking objects:  40% (25/62)   \rUnpacking objects:  41% (26/62)   \rUnpacking objects:  43% (27/62)   \rremote: Total 62 (delta 29), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  45% (28/62)   \rUnpacking objects:  46% (29/62)   \rUnpacking objects:  48% (30/62)   \rUnpacking objects:  50% (31/62)   \rUnpacking objects:  51% (32/62)   \rUnpacking objects:  53% (33/62)   \rUnpacking objects:  54% (34/62)   \rUnpacking objects:  56% (35/62)   \rUnpacking objects:  58% (36/62)   \rUnpacking objects:  59% (37/62)   \rUnpacking objects:  61% (38/62)   \rUnpacking objects:  62% (39/62)   \rUnpacking objects:  64% (40/62)   \rUnpacking objects:  66% (41/62)   \rUnpacking objects:  67% (42/62)   \rUnpacking objects:  69% (43/62)   \rUnpacking objects:  70% (44/62)   \rUnpacking objects:  72% (45/62)   \rUnpacking objects:  74% (46/62)   \rUnpacking objects:  75% (47/62)   \rUnpacking objects:  77% (48/62)   \rUnpacking objects:  79% (49/62)   \rUnpacking objects:  80% (50/62)   \rUnpacking objects:  82% (51/62)   \rUnpacking objects:  83% (52/62)   \rUnpacking objects:  85% (53/62)   \rUnpacking objects:  87% (54/62)   \rUnpacking objects:  88% (55/62)   \rUnpacking objects:  90% (56/62)   \rUnpacking objects:  91% (57/62)   \rUnpacking objects:  93% (58/62)   \rUnpacking objects:  95% (59/62)   \rUnpacking objects:  96% (60/62)   \rUnpacking objects:  98% (61/62)   \rUnpacking objects: 100% (62/62)   \rUnpacking objects: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gziWRyI1GcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import Modules\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from IPython.display import clear_output\n",
        "from eva4_lib.utils.dataloader_folders import create_dataset_csv_split, getTestData, getTrainData\n",
        "from eva4_lib.utils.range_test import lr_range_test\n",
        "from eva4_lib.utils.train_test import fit_generator\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ge6wxTWU7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bab83c8-b8fe-4fc7-9ce1-9aea7f20c3a7"
      },
      "source": [
        "## Model Tweak\n",
        "use_cuda= torch.cuda.is_available()\n",
        "device=torch.device('cuda' if use_cuda else 'cpu')\n",
        "\n",
        "def model_reset():\n",
        "    model = models.mobilenet_v2(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.last_channel, 4)\n",
        "    model = nn.Sequential(model, nn.LogSoftmax())\n",
        "    model = model.to(device)\n",
        "    summary(model, input_size=(3,224,224))\n",
        "\n",
        "model_reset()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "         Dropout-157                 [-1, 1280]               0\n",
            "          Linear-158                    [-1, 4]           5,124\n",
            "     MobileNetV2-159                    [-1, 4]               0\n",
            "      LogSoftmax-160                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 2,228,996\n",
            "Trainable params: 2,228,996\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.86\n",
            "Params size (MB): 8.50\n",
            "Estimated Total Size (MB): 161.94\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZVwAltgG9mN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "9f9687b6-2592-4420-aa8a-0c54eda48f97"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount =True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuDKiGTEqE9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Session\\ 2\\ Dataset.zip\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrgqoh8wi3_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c096fd1-609e-40d7-e72d-5e6c975ca55d"
      },
      "source": [
        "!du -sh Session\\ 2\\ Dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6G\tSession 2 Dataset/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPp74thUETI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "71d85b5b-5ad5-416f-83b8-9af7aca28008"
      },
      "source": [
        "path = \"/content/Session 2 Dataset/\"\n",
        "test_ratio = 0.2\n",
        "out_path = '/content/'\n",
        "\n",
        "create_dataset_csv_split(path, test_ratio, out_path)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 16582/16584 [00:02<00:00, 7291.91it/s]\n",
            "100%|██████████| 4148/4148 [00:00<00:00, 7243.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (16582, 2) , Test shape :  (4148, 2) , Labels shape :  (4, 2)\n",
            "Files (train.csv, test.csv and labels.csv) generated in :  /content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIy4Ucj2ZIwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = getTrainData('train.csv',128)\n",
        "test_loader = getTestData('test.csv',64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9j1ZjiXPzIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5a2acc2-09d6-4683-e9ec-f85280a6e799"
      },
      "source": [
        "lrs = [j*(10**i) for i in range(-3,-1) for j in range(1,11,2)]\n",
        "\n",
        "lr_range_test(lrs,model,device,train_loader, test_loader)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR: 0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "Loss=1.267850637435913 Batch_id=7 Accuracy=35.55:   6%|▌         | 8/130 [00:25<05:13,  2.57s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=1.1380987167358398 Batch_id=11 Accuracy=39.39:   9%|▉         | 12/130 [00:33<03:39,  1.86s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.9020001888275146 Batch_id=27 Accuracy=52.15:  22%|██▏       | 28/130 [01:08<03:19,  1.95s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5645566582679749 Batch_id=90 Accuracy=67.49:  70%|███████   | 91/130 [03:44<01:40,  2.57s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.4398914575576782 Batch_id=129 Accuracy=70.73: 100%|██████████| 130/130 [05:07<00:00,  2.37s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4733, Accuracy: 3371/4148 (81.27%)\n",
            "\n",
            "LR: 0.003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.5059201121330261 Batch_id=11 Accuracy=80.34:   9%|▉         | 12/130 [00:34<04:03,  2.07s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5314619541168213 Batch_id=51 Accuracy=79.78:  40%|████      | 52/130 [02:07<02:38,  2.03s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.477433979511261 Batch_id=71 Accuracy=80.06:  55%|█████▌    | 72/130 [02:57<01:44,  1.80s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.47820472717285156 Batch_id=129 Accuracy=80.85: 100%|██████████| 130/130 [05:06<00:00,  2.36s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3813, Accuracy: 3496/4148 (84.28%)\n",
            "\n",
            "LR: 0.005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.535646378993988 Batch_id=7 Accuracy=82.03:   6%|▌         | 8/130 [00:23<05:01,  2.48s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.49238938093185425 Batch_id=17 Accuracy=82.90:  14%|█▍        | 18/130 [00:45<03:40,  1.97s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.384597510099411 Batch_id=109 Accuracy=82.48:  85%|████████▍ | 110/130 [04:21<00:35,  1.76s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5259089469909668 Batch_id=129 Accuracy=82.52: 100%|██████████| 130/130 [05:08<00:00,  2.38s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3664, Accuracy: 3552/4148 (85.63%)\n",
            "\n",
            "LR: 0.007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.5295524597167969 Batch_id=2 Accuracy=79.43:   2%|▏         | 3/130 [00:17<16:33,  7.82s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.468910276889801 Batch_id=11 Accuracy=81.90:   9%|▉         | 12/130 [00:35<03:50,  1.95s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.3641468286514282 Batch_id=15 Accuracy=82.81:  12%|█▏        | 16/130 [00:47<03:47,  2.00s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5557553768157959 Batch_id=35 Accuracy=83.49:  28%|██▊       | 36/130 [01:32<02:35,  1.65s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.4671861231327057 Batch_id=129 Accuracy=83.70: 100%|██████████| 130/130 [05:12<00:00,  2.41s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3395, Accuracy: 3588/4148 (86.50%)\n",
            "\n",
            "LR: 0.009000000000000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.2663573622703552 Batch_id=15 Accuracy=85.50:  12%|█▏        | 16/130 [00:44<04:09,  2.19s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.19349601864814758 Batch_id=16 Accuracy=85.94:  13%|█▎        | 17/130 [00:45<03:32,  1.88s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.22064216434955597 Batch_id=129 Accuracy=84.55: 100%|██████████| 130/130 [05:18<00:00,  2.45s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3302, Accuracy: 3610/4148 (87.03%)\n",
            "\n",
            "LR: 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.3987785279750824 Batch_id=3 Accuracy=86.72:   3%|▎         | 4/130 [00:14<09:28,  4.51s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.2856564521789551 Batch_id=9 Accuracy=86.48:   8%|▊         | 10/130 [00:32<05:51,  2.93s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.35028114914894104 Batch_id=29 Accuracy=86.56:  23%|██▎       | 30/130 [01:26<04:42,  2.82s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.26987385749816895 Batch_id=129 Accuracy=85.65: 100%|██████████| 130/130 [05:18<00:00,  2.45s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3246, Accuracy: 3606/4148 (86.93%)\n",
            "\n",
            "LR: 0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.34173348546028137 Batch_id=11 Accuracy=86.00:   9%|▉         | 12/130 [00:31<03:45,  1.91s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5646575093269348 Batch_id=20 Accuracy=84.15:  16%|█▌        | 21/130 [00:53<04:22,  2.41s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5351552963256836 Batch_id=57 Accuracy=81.16:  45%|████▍     | 58/130 [02:26<02:57,  2.47s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.35245200991630554 Batch_id=117 Accuracy=80.33:  91%|█████████ | 118/130 [04:55<00:23,  1.95s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.3915609121322632 Batch_id=129 Accuracy=80.37: 100%|██████████| 130/130 [05:21<00:00,  2.47s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4599, Accuracy: 3381/4148 (81.51%)\n",
            "\n",
            "LR: 0.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.4375258982181549 Batch_id=3 Accuracy=83.98:   3%|▎         | 4/130 [00:15<09:22,  4.47s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5392550230026245 Batch_id=129 Accuracy=78.05: 100%|██████████| 130/130 [05:21<00:00,  2.47s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5236, Accuracy: 3304/4148 (79.65%)\n",
            "\n",
            "LR: 0.07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.4710504710674286 Batch_id=0 Accuracy=82.03:   1%|          | 1/130 [00:12<27:14, 12.67s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5313015580177307 Batch_id=21 Accuracy=78.37:  17%|█▋        | 22/130 [00:58<03:37,  2.02s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5001306533813477 Batch_id=38 Accuracy=78.45:  30%|███       | 39/130 [01:40<02:51,  1.89s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.6386712193489075 Batch_id=75 Accuracy=78.07:  58%|█████▊    | 76/130 [03:08<01:35,  1.76s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5018123984336853 Batch_id=129 Accuracy=77.57: 100%|██████████| 130/130 [05:11<00:00,  2.39s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6112, Accuracy: 3057/4148 (73.70%)\n",
            "\n",
            "LR: 0.09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.47041773796081543 Batch_id=6 Accuracy=77.12:   5%|▌         | 7/130 [00:20<06:00,  2.93s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.5014060139656067 Batch_id=7 Accuracy=77.44:   6%|▌         | 8/130 [00:24<06:23,  3.15s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.645252525806427 Batch_id=10 Accuracy=76.78:   8%|▊         | 11/130 [00:28<03:55,  1.98s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=0.7513758540153503 Batch_id=41 Accuracy=77.59:  32%|███▏      | 42/130 [01:49<04:31,  3.09s/it]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "Loss=2.7187817096710205 Batch_id=129 Accuracy=73.97: 100%|██████████| 130/130 [05:06<00:00,  2.36s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 60.5975, Accuracy: 796/4148 (19.19%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LRs used for range  test :  [0.001, 0.003, 0.005, 0.007, 0.009000000000000001, 0.01, 0.03, 0.05, 0.07, 0.09]\n",
            "Train Accuracies :  [70.72729465685683, 80.85273187793993, 82.51718731154264, 83.69919189482572, 84.54951151851405, 85.65311783862019, 80.37028102762031, 78.05451694608612, 77.5660354601375, 73.9717766252563]\n",
            "Test acc:  85.65311783862019 LR:  0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYttT072eDsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "5d51aec6-a799-41bb-a924-6379dbc23449"
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,  momentum=0.9)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.01,  total_steps=20, pct_start=0.3, final_div_factor=1, div_factor=10)\n",
        "\n",
        "fit_generator(model, device, train_loader, test_loader, optimizer, scheduler, start_epoch = 1, num_epoch = 5, plot_acc = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Learning_Rate 0.0009999999999999992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.2954535484313965 Batch_id=129 Accuracy=40.56: 100%|██████████| 130/130 [05:17<00:00,  2.44s/it]\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.3171, Accuracy: 1753/4148 (42.26%)\n",
            "\n",
            "Epoch: 2 Learning_Rate 0.001859423525312735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.3543144464492798 Batch_id=129 Accuracy=40.33: 100%|██████████| 130/130 [05:15<00:00,  2.43s/it]\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2937, Accuracy: 1761/4148 (42.45%)\n",
            "\n",
            "Epoch: 3 Learning_Rate 0.004109423525312736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.2829608917236328 Batch_id=129 Accuracy=41.18: 100%|██████████| 130/130 [05:21<00:00,  2.47s/it]\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2428, Accuracy: 1799/4148 (43.37%)\n",
            "\n",
            "Epoch: 4 Learning_Rate 0.006890576474687262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.1819852590560913 Batch_id=129 Accuracy=43.33: 100%|██████████| 130/130 [05:18<00:00,  2.45s/it]\n",
            "  0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1834, Accuracy: 1998/4148 (48.17%)\n",
            "\n",
            "Epoch: 5 Learning_Rate 0.009140576474687263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.2052946090698242 Batch_id=69 Accuracy=45.98:  53%|█████▎    | 69/130 [02:56<01:56,  1.92s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQuRolHr5gKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "210b9cad-812a-415e-d572-0606c7441664"
      },
      "source": [
        "fail=[]\n",
        "for eval_data, eval_target in test_loader:\n",
        "  eval_data, eval_target = eval_data.to(device), eval_target.to(device)\n",
        "  eval_out = model(eval_data)\n",
        "  target_lbl=eval_target.cpu().numpy()\n",
        "  pred_lbl=eval_out.argmax(1).cpu().numpy()\n",
        "  #print(pred_lbl)\n",
        "  #print(eval_target)\n",
        "  for i in range(64):\n",
        "    if target_lbl[i] != pred_lbl[i]:fail.append([eval_data[i].cpu(),target_lbl[i],pred_lbl[i],eval_out[i,target_lbl[i]].cpu(),eval_out()[i,pred_lbl[i]].cpu()])\n",
        "  \n",
        "  print('fail_count : '+str(len(fail)))\n",
        "  if len(fail)>100: break\n",
        "\n",
        "print('Returned Miscalssified images # : {}'.format(len(fail)))\n",
        "print('** Note : If count of returned image is less than {}, then there arent enough misclassified images in the loader passed'.format(100))\n",
        "\n",
        "\n",
        "  # fig = plt.figure(figsize=(16,16))\n",
        "  # cnt=0\n",
        "  # for i in fail[:25]:\n",
        "  #   ax=fig.add_subplot(5, 5, cnt+1)\n",
        "  #   img=np.squeeze(eval_data[i].cpu().numpy()[0])\n",
        "  #   ax.imshow(img)\n",
        "  #   cnt+=1\n",
        "  #   ax.set_title(\"Actual : \"+str(target_lbl[i])+\"  Predicted : \"+str(pred_lbl[i]))\n",
        "  # plt.savefig('L1_Misclassified.png')\n",
        "  # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fail_count : 6\n",
            "fail_count : 10\n",
            "fail_count : 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-adf993ae2360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0meval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtarget_lbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpred_lbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 350\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 11.17 GiB total capacity; 10.29 GiB already allocated; 31.81 MiB free; 10.83 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn0SYJJe23_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(torch.device('cpu'))\n",
        "model.eval()\n",
        "traced_model = torch.jit.trace(model,torch.randn(1,3,244,244))\n",
        "traced_model.save(\"Sess2_mobilenetv2_4.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7tpvOVYgOjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}